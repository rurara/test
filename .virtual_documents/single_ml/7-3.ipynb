from tensorflow import keras
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()



from sklearn.model_selection import train_test_split
train_scaled = train_input / 255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)
train_scaled.shape


def model_fn(a_layer=None):
    model = keras.Sequential()
    model.add(keras.layers.Flatten(input_shape=(28,28)))
    model.add(keras.layers.Dense(100,activation='relu'))
    if a_layer:
        model.add(a_layer)
    model.add(keras.layers.Dense(10,activation='softmax'))
    return model
                                 


model = model_fn()
model.summary()


model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')
history = model.fit(train_scaled, train_target, epochs=5, verbose=0)


print(history.history.keys())
history.history


import matplotlib.pyplot as plt 
plt.plot(history.history['loss'])
plt.xlabel('ep')
plt.ylabel('lo')
plt.show()


import matplotlib.pyplot as plt 
plt.plot(history.history['accuracy'])
plt.xlabel('ep')
plt.ylabel('acc')
plt.show()


model = model_fn()
model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')
history=model.fit(train_scaled, train_target, epochs=20, verbose=0)




plt.plot(history.history['loss'])
plt.plot(history.history['accuracy'])
plt.xlabel('ep')
plt.ylabel('lo')
plt.show()


model = model_fn()
model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')
history=model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target))



history.history.keys()



plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.xlabel('ep')
plt.ylabel('lo')
plt.show()


model = model_fn()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
history=model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target))




plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
# plt.plot(history.history['accuracy'])
# plt.plot(history.history['val_accuracy'])
plt.xlabel('ep')
plt.ylabel('lo')
plt.show()


model=model_fn(keras.layers.Dropout(0.3))
model.summary()


model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
history=model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target))




plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('ep')
plt.ylabel('lo')
plt.show()


model=model_fn(keras.layers.Dropout(0.3))
model.summary()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
history=model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target))



model.save_weights('model-weights.h5')


model.save('model-whole.keras')


get_ipython().getoutput("ls -al *.h5")
get_ipython().getoutput("ls -al *.keras")


model=model_fn(keras.layers.Dropout(0.3))
model.load_weights('model-weights.h5')


import numpy as np
val_labels=np.argmax(model.predict(val_scaled),axis=-1)
np.mean(val_labels==val_target)


model = keras.models.load_model('model-whole.h5')
model.evaluate(val_scaled,val_target)


model=model_fn(keras.layers.Dropout(0.3))
model.summary()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
checkpoint_cb=keras.callbacks.ModelCheckpoint('best-model.h5')
history=model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb])



model = keras.models.load_model('best-model.h5')
model.evaluate(val_scaled,val_target)


model=model_fn(keras.layers.Dropout(0.3))
model.summary()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
checkpoint_cb=keras.callbacks.ModelCheckpoint('best-model.h5')
early_stopping_cb=keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)
history=model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb])



early_stopping_cb.stopped_epoch



plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('ep')
plt.ylabel('lo')
plt.show()



