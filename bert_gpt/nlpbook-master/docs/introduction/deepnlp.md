---
layout: default
title: Deep NLP
parent: Introduction
nav_order: 1
---

# 딥러닝 기반 자연어 처리 모델
{: .no_toc }

이 글에서는 딥러닝(Deep Learning) 기반 자연어 처리 모델의 개념과 학습 방법 등을 살펴봅니다.
{: .fs-4 .ls-1 .code-example }

## Table of contents
{: .no_toc .text-delta .mt-6}

1. TOC
{:toc}

---

## 기계의 자연어 처리

컴퓨터는 계산기일 뿐입니다. 자비스\* 같이 사람 말을 알아듣는 인공지능이 등장하더라도 그 이해의 본질은 계산(computation) 내지 처리(processing)일 뿐입니다. 사람의 자연어 이해(understanding)와는 차이가 있다는 것이지요.

\* 자비스(J.A.R.V.I.S)는 마블 시네마틱 유니버스에 등장하는 토니 스타크의 인공지능 비서입니다.
{: .fs-4 .ls-1 .code-example }

그렇다면 기계가 사람 말을 알아듣는 것처럼 보이게 하려면 어떤 요소들이 있어야 할까요? 우선은 **모델(model)**이라는 개념부터 소개해 보겠습니다. 모델은 입력을 받아 어떤 처리를 수행하는 **함수(function)**입니다.

## **그림1** 모델
{: .no_toc .text-delta }
<img src="https://i.imgur.com/vcW4VPS.png" width="400px" title="source: imgur.com" />

그림1에서 확인할 수 있듯 모델의 출력은 **확률(probability)**이라는 점에 주목할 필요가 있습니다. 확률이란 어떤 사건이 나타날 가능성에 대한 수치이며 그 값은 0에서 1 사이의 값으로 나타냅니다. 따라서 모델은 어떤 입력을 받아서 해당 입력이 특정 범주일 확률을 반환하는 <U>확률</U>함수(probability function)입니다.

그렇다면 자연어 처리 모델의 입력은 무엇일까요? 사람 말, 즉 자연어입니다. 자연어 처리 모델은 <U>자연어 입력을 받아서</U> 해당 입력이 특정 범주일 확률을 반환하는 확률함수입니다.

예를 들어 우리가 영화 리뷰의 **감성(sentiment)**을 맞히는 자연어 처리 모델을 만든다고 가정해 봅시다. 그러면 우리가 만든 감성 분석 모델은 수식1처럼 함수 $f$로 써볼 수 있습니다. 이 모델은 모델은 자연어(문장)를 입력받아 복잡한 내부 계산 과정을 거쳐서 해당 문장이 긍정(positive)일 확률, 중립(neutral)일 확률, 부정(negative)일 확률을 출력합니다. 

## **수식1** 자연어 처리 모델
{: .no_toc .text-delta }

$$
\begin{align*}
f\left( \text{재미가 없는 편인 영화에요} \right) = [ 0.0, 0.3, 0.7 ] \\
f\left( \text{단언컨대 이 영화 재미 있어요} \right) = [ 1.0, 0.0, 0.0 ]
\end{align*}
$$

모델 종류는 정말 다양합니다. 입력(자연어) 특성과 목적(감성 분석) 등에 따라 최적이라고 판단되는 걸 선택하면 됩니다. 비유하자면 마트에 진열된 수많은 상품 가운데 오늘 저녁 식사에 어울리는 재료를 고르는 것과 같습니다.

그러면 요즘 가장 인기 있는 모델 종류는 무엇일까요? 바로 **딥러닝(deep learning)**입니다. 기존의 다른 구조보다 성능이 월등히 좋기 때문입니다. 딥러닝이란 데이터 패턴을 스스로 익히는 인공 지능의 한 갈래입니다. 여기에서 '딥(deep)'이란 많은 **은닉층(hidden layer)**을 사용한다는 의미입니다. 딥 러닝은 이미지 분류, 음성 인식 및 합성, 자연어 처리 등. 다양한 분야에서 널리 쓰이고 있습니다. 

딥러닝 가운데서도 **BERT(Bidirectional Encoder Representations from Transformers)**나 **GPT(Generative Pre-trained Transformer)** 등이 특히 주목받고 있습니다. 이들을 <U>딥러닝 기반 자연어 처리 모델</U>이라고 부릅니다.


## **그림2** 딥러닝 기반 자연어 처리 모델
{: .no_toc .text-delta }
<img src="https://i.imgur.com/CPBZIDM.png" width="400px" title="source: imgur.com" />


딥러닝 기반 자연어 처리 모델의 출력 역시 확률입니다. 하지만 사람은 자연어 형태의 출력을 선호합니다. 그것이 이해하기 쉽기도 하고요. 따라서 출력된 확률을 후처리(post processing)해서 자연어 형태로 바꿔줍니다.

- 재미가 없는 편인 영화에요 → [0.0, 0.3, 0.7] → 부정(negative)
- 단언컨대 이 영화 재미 있어요 → [1.0, 0.0, 0.0] → 긍정(positive)

이처럼 자연어 처리 모델은 자연어를 입력받아 해당 입력이 특정 범주일 확률을 출력하고, 이 확률값들을 적당히 후처리해서 자연어 형태로 가공해 반환합니다. 이 책에서 다루는 **문서 분류(document classification)**, **질의 응답(question answering)**, **개체명 인식(named entity recognition)**, **문장 생성(sentence generation)** 등 과제가 모두 그렇습니다.

만일 사람 말을 정말 잘 알아듣는 것처럼 보이는 인공지능이 있다면 이 일련의 계산 과정으로 나온 최종 결과가 그럴싸하게 보이기 때문일 것입니다. 많은 연구자와 개발자들이 성능 좋은 자연어 처리 모델을 만들기 위해 고군분투하고 있습니다.


---

## 딥러닝 모델의 학습

딥러닝 자연어 처리 모델을 만들려면 무엇을 해야 할까요? 우선 데이터부터 준비해야 합니다. 다음처럼 각 문장에 '감성'이라는 **레이블(label)**을 달아놓은 자료가 필요합니다. 이를 **학습 데이터(training data)**라고 부릅니다.

## **표1** 감성 분석 학습 데이터
{: .no_toc .text-delta }

|문장|긍정|중립|부정|
|---|---|---|---|
|단언컨대 이 영화 재미 있어요|1|0|0|
|단언컨대 이 영화 재미 없어요|0|0|1|
|...|...|...|...|


그다음은 모델이 데이터의 패턴(pattern)을 스스로 익히게 해야 합니다. 이런 과정을 **학습(train)**이라고 합니다. `단언컨대 이 영화 재미 있어요` 문장을 학습하는 상황이라고 가정해 봅시다. 학습 초기에 확률 함수 $f$는 `단언컨대 이 영화 재미 있어요`를 입력 받으면 아래처럼 출력할 겁니다. 문장이 어떤 감성인지 전혀 모르는 상황이죠.


## **그림1** 감성 분석 모델의 출력 (1)
{: .no_toc .text-delta }
<img src="https://i.imgur.com/YUyysLA.jpg" width="250px" title="source: imgur.com" />

그런데 우리는 이 문장의 감성, 즉 정답이 $\begin{bmatrix} 1 & 0 & 0 \end{bmatrix}$임을 알고 있습니다. 그런데 현재 모델의 출력(아래 그림의 회색 막대)과 정답을 비교해 보면 중립/부정 확률은 높고 긍정 확률은 낮습니다. 따라서 $f$가 `단언컨대 이 영화 재미 있어요`라는 입력을 받았을 때 긍정 점수는 높이고, 중립/부정 점수는 낮추도록 모델 전체를 업데이트합니다.

## **그림2** 감성 분석 모델의 출력 (2)
{: .no_toc .text-delta }
<img src="https://i.imgur.com/nTBwj6u.jpg" width="250px" title="source: imgur.com" />

업데이트를 했는데도 모델의 출력이 여전히 정답과 차이가 있다면 한 번 더 조정해 줍니다.

## **그림3** 감성 분석 모델의 출력 (3)
{: .no_toc .text-delta }
<img src="https://i.imgur.com/e87KFzd.jpg" width="250px" title="source: imgur.com" />

이런 업데이트를 여러번 수행하면 종국에는 $f$가 아래 그림처럼 정답에 가까운 출력을 낼 수 있습니다. 이렇게 모델을 업데이트하는 과정 전체를 **학습(train)**이라고 부릅니다. 모델이 입력-출력 사이의 패턴을 스스로 익히는 과정인 거죠.

## **그림4** 감성 분석 모델의 출력 (4)
{: .no_toc .text-delta }
<img src="https://i.imgur.com/5Dzq7Qz.jpg" width="250px" title="source: imgur.com" />


---